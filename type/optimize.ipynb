{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                    id  category\n",
       "0      2_trans_497.csv         1\n",
       "1      2_trans_483.csv         1\n",
       "2     2_trans_2396.csv         1\n",
       "3     2_trans_1847.csv         1\n",
       "4     2_trans_2382.csv         1\n",
       "...                ...       ...\n",
       "2095  2_trans_1679.csv         1\n",
       "2096  2_trans_2370.csv         1\n",
       "2097  2_trans_1692.csv         1\n",
       "2098  2_trans_1876.csv         4\n",
       "2099  2_trans_1862.csv         1\n",
       "\n",
       "[2100 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2_trans_497.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2_trans_483.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2_trans_2396.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2_trans_1847.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2_trans_2382.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2095</th>\n      <td>2_trans_1679.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2096</th>\n      <td>2_trans_2370.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2097</th>\n      <td>2_trans_1692.csv</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2098</th>\n      <td>2_trans_1876.csv</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2099</th>\n      <td>2_trans_1862.csv</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>2100 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 115
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.integrate as it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 2100/2100 [00:17<00:00, 122.83it/s]\n"
     ]
    }
   ],
   "source": [
    "data_train_path = './data_train/data_train/'\n",
    "for file in tqdm(os.listdir(data_train_path)):\n",
    "    data_df = pd.read_csv(data_train_path + file)\n",
    "    for name in data_df.columns:\n",
    "        data_df[name + \"_integ\"] = [0] + it.cumtrapz(data_df[name]).tolist()\n",
    "    data_df.to_csv('./data_train/data_train_i/'+ file, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0      0.001202\n",
       "1      0.001202\n",
       "2      0.001201\n",
       "3      0.001201\n",
       "4      0.001201\n",
       "         ...   \n",
       "415    0.002276\n",
       "416    0.002281\n",
       "417    0.002285\n",
       "418    0.002290\n",
       "419    0.002294\n",
       "Name: H2, Length: 420, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 123
    }
   ],
   "source": [
    "example_df['H2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def flatten_data(\n",
    "                base_columns_names,\n",
    "                columns_repeat_n, \n",
    "                data_path, \n",
    "                file_names, \n",
    "                categories=None,):\n",
    "    columns = []\n",
    "    for i in range(columns_repeat_n):\n",
    "        for name in base_columns_names:\n",
    "            columns.append(str(i) + \"_\" + name)\n",
    "    if categories != None:\n",
    "        columns.append(\"category\")\n",
    "\n",
    "    data = []\n",
    "    for i in tqdm(range(len(file_names))):\n",
    "        new_row = pd.read_csv(data_path + file_names[i]).values.flatten()\n",
    "        if categories != None:\n",
    "            new_row = np.append(new_row, categories[i])\n",
    "        data.append(dict(zip(columns, new_row)))\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 2100/2100 [00:04<00:00, 516.74it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          0_H2      0_CO    0_C2H4    0_C2H2      1_H2      1_CO    1_C2H4  \\\n",
       "0     0.001202  0.029565  0.001069  0.000251  0.001202  0.029563  0.001068   \n",
       "1     0.001875  0.030855  0.002613  0.000068  0.001877  0.030871  0.002618   \n",
       "2     0.000947  0.021001  0.001025  0.000056  0.000947  0.021017  0.001028   \n",
       "3     0.000720  0.017019  0.004584  0.000274  0.000719  0.017011  0.004582   \n",
       "4     0.001791  0.009544  0.007192  0.000238  0.001791  0.009540  0.007192   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2095  0.001043  0.009424  0.002751  0.000102  0.001043  0.009426  0.002751   \n",
       "2096  0.000631  0.023220  0.003757  0.000110  0.000633  0.023252  0.003764   \n",
       "2097  0.002005  0.020167  0.002409  0.000268  0.002006  0.020171  0.002410   \n",
       "2098  0.002933  0.008451  0.000209  0.000285  0.002935  0.008469  0.000214   \n",
       "2099  0.001545  0.024891  0.002929  0.000135  0.001545  0.024891  0.002928   \n",
       "\n",
       "        1_C2H2      2_H2      2_CO  ...  417_C2H2    418_H2    418_CO  \\\n",
       "0     0.000251  0.001201  0.029562  ...  0.000344  0.002290  0.042025   \n",
       "1     0.000068  0.001879  0.030887  ...  0.000144  0.002758  0.037074   \n",
       "2     0.000056  0.000947  0.021032  ...  0.000251  0.001810  0.036797   \n",
       "3     0.000274  0.000718  0.017003  ...  0.000310  0.001653  0.027981   \n",
       "4     0.000238  0.001791  0.009536  ...  0.000345  0.002087  0.014080   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2095  0.000102  0.001043  0.009428  ...  0.000208  0.002142  0.011869   \n",
       "2096  0.000111  0.000636  0.023284  ...  0.000365  0.001103  0.035729   \n",
       "2097  0.000268  0.002007  0.020175  ...  0.000291  0.004327  0.031645   \n",
       "2098  0.000285  0.002938  0.008487  ...  0.000451  0.003756  0.022034   \n",
       "2099  0.000135  0.001545  0.024891  ...  0.000156  0.001836  0.034614   \n",
       "\n",
       "      418_C2H4  418_C2H2    419_H2    419_CO  419_C2H4  419_C2H2  category  \n",
       "0     0.004610  0.000345  0.002294  0.042099  0.004630  0.000345       1.0  \n",
       "1     0.006487  0.000145  0.002764  0.037128  0.006520  0.000146       1.0  \n",
       "2     0.002978  0.000252  0.001816  0.036885  0.002999  0.000253       1.0  \n",
       "3     0.008585  0.000310  0.001659  0.028044  0.008604  0.000310       1.0  \n",
       "4     0.013222  0.000346  0.002091  0.014124  0.013251  0.000347       1.0  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "2095  0.006679  0.000208  0.002149  0.011889  0.006705  0.000209       1.0  \n",
       "2096  0.007496  0.000367  0.001105  0.035809  0.007522  0.000368       1.0  \n",
       "2097  0.004681  0.000291  0.004339  0.031754  0.004703  0.000291       1.0  \n",
       "2098  0.004513  0.000452  0.003762  0.022104  0.004537  0.000454       4.0  \n",
       "2099  0.003589  0.000156  0.001837  0.034674  0.003593  0.000156       1.0  \n",
       "\n",
       "[2100 rows x 1681 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0_H2</th>\n      <th>0_CO</th>\n      <th>0_C2H4</th>\n      <th>0_C2H2</th>\n      <th>1_H2</th>\n      <th>1_CO</th>\n      <th>1_C2H4</th>\n      <th>1_C2H2</th>\n      <th>2_H2</th>\n      <th>2_CO</th>\n      <th>...</th>\n      <th>417_C2H2</th>\n      <th>418_H2</th>\n      <th>418_CO</th>\n      <th>418_C2H4</th>\n      <th>418_C2H2</th>\n      <th>419_H2</th>\n      <th>419_CO</th>\n      <th>419_C2H4</th>\n      <th>419_C2H2</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.001202</td>\n      <td>0.029565</td>\n      <td>0.001069</td>\n      <td>0.000251</td>\n      <td>0.001202</td>\n      <td>0.029563</td>\n      <td>0.001068</td>\n      <td>0.000251</td>\n      <td>0.001201</td>\n      <td>0.029562</td>\n      <td>...</td>\n      <td>0.000344</td>\n      <td>0.002290</td>\n      <td>0.042025</td>\n      <td>0.004610</td>\n      <td>0.000345</td>\n      <td>0.002294</td>\n      <td>0.042099</td>\n      <td>0.004630</td>\n      <td>0.000345</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.001875</td>\n      <td>0.030855</td>\n      <td>0.002613</td>\n      <td>0.000068</td>\n      <td>0.001877</td>\n      <td>0.030871</td>\n      <td>0.002618</td>\n      <td>0.000068</td>\n      <td>0.001879</td>\n      <td>0.030887</td>\n      <td>...</td>\n      <td>0.000144</td>\n      <td>0.002758</td>\n      <td>0.037074</td>\n      <td>0.006487</td>\n      <td>0.000145</td>\n      <td>0.002764</td>\n      <td>0.037128</td>\n      <td>0.006520</td>\n      <td>0.000146</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000947</td>\n      <td>0.021001</td>\n      <td>0.001025</td>\n      <td>0.000056</td>\n      <td>0.000947</td>\n      <td>0.021017</td>\n      <td>0.001028</td>\n      <td>0.000056</td>\n      <td>0.000947</td>\n      <td>0.021032</td>\n      <td>...</td>\n      <td>0.000251</td>\n      <td>0.001810</td>\n      <td>0.036797</td>\n      <td>0.002978</td>\n      <td>0.000252</td>\n      <td>0.001816</td>\n      <td>0.036885</td>\n      <td>0.002999</td>\n      <td>0.000253</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000720</td>\n      <td>0.017019</td>\n      <td>0.004584</td>\n      <td>0.000274</td>\n      <td>0.000719</td>\n      <td>0.017011</td>\n      <td>0.004582</td>\n      <td>0.000274</td>\n      <td>0.000718</td>\n      <td>0.017003</td>\n      <td>...</td>\n      <td>0.000310</td>\n      <td>0.001653</td>\n      <td>0.027981</td>\n      <td>0.008585</td>\n      <td>0.000310</td>\n      <td>0.001659</td>\n      <td>0.028044</td>\n      <td>0.008604</td>\n      <td>0.000310</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.001791</td>\n      <td>0.009544</td>\n      <td>0.007192</td>\n      <td>0.000238</td>\n      <td>0.001791</td>\n      <td>0.009540</td>\n      <td>0.007192</td>\n      <td>0.000238</td>\n      <td>0.001791</td>\n      <td>0.009536</td>\n      <td>...</td>\n      <td>0.000345</td>\n      <td>0.002087</td>\n      <td>0.014080</td>\n      <td>0.013222</td>\n      <td>0.000346</td>\n      <td>0.002091</td>\n      <td>0.014124</td>\n      <td>0.013251</td>\n      <td>0.000347</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2095</th>\n      <td>0.001043</td>\n      <td>0.009424</td>\n      <td>0.002751</td>\n      <td>0.000102</td>\n      <td>0.001043</td>\n      <td>0.009426</td>\n      <td>0.002751</td>\n      <td>0.000102</td>\n      <td>0.001043</td>\n      <td>0.009428</td>\n      <td>...</td>\n      <td>0.000208</td>\n      <td>0.002142</td>\n      <td>0.011869</td>\n      <td>0.006679</td>\n      <td>0.000208</td>\n      <td>0.002149</td>\n      <td>0.011889</td>\n      <td>0.006705</td>\n      <td>0.000209</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2096</th>\n      <td>0.000631</td>\n      <td>0.023220</td>\n      <td>0.003757</td>\n      <td>0.000110</td>\n      <td>0.000633</td>\n      <td>0.023252</td>\n      <td>0.003764</td>\n      <td>0.000111</td>\n      <td>0.000636</td>\n      <td>0.023284</td>\n      <td>...</td>\n      <td>0.000365</td>\n      <td>0.001103</td>\n      <td>0.035729</td>\n      <td>0.007496</td>\n      <td>0.000367</td>\n      <td>0.001105</td>\n      <td>0.035809</td>\n      <td>0.007522</td>\n      <td>0.000368</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2097</th>\n      <td>0.002005</td>\n      <td>0.020167</td>\n      <td>0.002409</td>\n      <td>0.000268</td>\n      <td>0.002006</td>\n      <td>0.020171</td>\n      <td>0.002410</td>\n      <td>0.000268</td>\n      <td>0.002007</td>\n      <td>0.020175</td>\n      <td>...</td>\n      <td>0.000291</td>\n      <td>0.004327</td>\n      <td>0.031645</td>\n      <td>0.004681</td>\n      <td>0.000291</td>\n      <td>0.004339</td>\n      <td>0.031754</td>\n      <td>0.004703</td>\n      <td>0.000291</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2098</th>\n      <td>0.002933</td>\n      <td>0.008451</td>\n      <td>0.000209</td>\n      <td>0.000285</td>\n      <td>0.002935</td>\n      <td>0.008469</td>\n      <td>0.000214</td>\n      <td>0.000285</td>\n      <td>0.002938</td>\n      <td>0.008487</td>\n      <td>...</td>\n      <td>0.000451</td>\n      <td>0.003756</td>\n      <td>0.022034</td>\n      <td>0.004513</td>\n      <td>0.000452</td>\n      <td>0.003762</td>\n      <td>0.022104</td>\n      <td>0.004537</td>\n      <td>0.000454</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>2099</th>\n      <td>0.001545</td>\n      <td>0.024891</td>\n      <td>0.002929</td>\n      <td>0.000135</td>\n      <td>0.001545</td>\n      <td>0.024891</td>\n      <td>0.002928</td>\n      <td>0.000135</td>\n      <td>0.001545</td>\n      <td>0.024891</td>\n      <td>...</td>\n      <td>0.000156</td>\n      <td>0.001836</td>\n      <td>0.034614</td>\n      <td>0.003589</td>\n      <td>0.000156</td>\n      <td>0.001837</td>\n      <td>0.034674</td>\n      <td>0.003593</td>\n      <td>0.000156</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2100 rows × 1681 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 126
    }
   ],
   "source": [
    "data_train_i_path = './data_train/data_train/'\n",
    "example_df = pd.read_csv(data_train_i_path + '2_trans_497.csv')\n",
    "out_df = flatten_data(example_df.columns, len(example_df), data_train_i_path, train_df['id'].to_list(), train_df['category'].to_list())\n",
    "out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    " X_train, X_test, y_train, y_test = train_test_split(out_df.drop('category', axis=1), out_df['category'], test_size=0.15, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "count    2100.000000\n",
       "mean        1.425714\n",
       "std         0.950768\n",
       "min         1.000000\n",
       "25%         1.000000\n",
       "50%         1.000000\n",
       "75%         1.000000\n",
       "max         4.000000\n",
       "Name: category, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "source": [
    "out_df['category'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "#clf.fit(out_df.drop('category', axis=1), out_df['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9492063492063492"
      ]
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([4.])"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "clf.predict([out_df.drop('category', axis=1).iloc[2098]])"
   ]
  },
  {
   "source": [
    "# Тенсорка входит в здание"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = out_df.pop('category')\n",
    "dataset = tf.data.Dataset.from_tensor_slices((out_df.values, target.values-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset.shuffle(len(out_df)).batch(1)\n",
    "def get_compiled_model():\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(500, activation='relu'),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(30, activation='relu'),\n",
    "    tf.keras.layers.Dense(4)\n",
    "  ])\n",
    "\n",
    "  model.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      " 948/2100 [============>.................] - ETA: 6s - loss: 0.4437 - accuracy: 0.8344"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-83cbca72f3cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_compiled_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/transformer/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1103\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/transformer/venv/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \"\"\"\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "model.fit(train_dataset, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 900/900 [00:01<00:00, 516.75it/s]\n"
     ]
    }
   ],
   "source": [
    "data_test_dir = './data_test/data_test/'\n",
    "example_test_df = pd.read_csv(data_test_dir + os.listdir(data_test_dir)[0])\n",
    "test_file_names = os.listdir(data_test_dir)\n",
    "test_complete_df = flatten_data(example_test_df.columns, len(example_test_df), data_test_dir, test_file_names)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = []\n",
    "predicts = clf.predict(test_complete_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'id': os.listdir(data_test_dir), 'category': predicts.astype('int')}, index=None).to_csv('test.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}