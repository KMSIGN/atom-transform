{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                    id  predicted\n",
       "0      2_trans_497.csv        550\n",
       "1      2_trans_483.csv       1093\n",
       "2     2_trans_2396.csv        861\n",
       "3     2_trans_1847.csv       1093\n",
       "4     2_trans_2382.csv        488\n",
       "...                ...        ...\n",
       "2095  2_trans_1679.csv       1093\n",
       "2096  2_trans_2370.csv        805\n",
       "2097  2_trans_1692.csv        476\n",
       "2098  2_trans_1876.csv        550\n",
       "2099  2_trans_1862.csv       1093\n",
       "\n",
       "[2100 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>predicted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2_trans_497.csv</td>\n      <td>550</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2_trans_483.csv</td>\n      <td>1093</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2_trans_2396.csv</td>\n      <td>861</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2_trans_1847.csv</td>\n      <td>1093</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2_trans_2382.csv</td>\n      <td>488</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2095</th>\n      <td>2_trans_1679.csv</td>\n      <td>1093</td>\n    </tr>\n    <tr>\n      <th>2096</th>\n      <td>2_trans_2370.csv</td>\n      <td>805</td>\n    </tr>\n    <tr>\n      <th>2097</th>\n      <td>2_trans_1692.csv</td>\n      <td>476</td>\n    </tr>\n    <tr>\n      <th>2098</th>\n      <td>2_trans_1876.csv</td>\n      <td>550</td>\n    </tr>\n    <tr>\n      <th>2099</th>\n      <td>2_trans_1862.csv</td>\n      <td>1093</td>\n    </tr>\n  </tbody>\n</table>\n<p>2100 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.integrate as it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "norms = {\n",
    "    'H2': 0.005,\n",
    "    'CH4': 0.008,\n",
    "    'C2H6': 0.006,\n",
    "    'C2H2': 0.0008,\n",
    "    'CO': 0.053,\n",
    "    'CO2': 0.52\n",
    "}\n",
    "data_train_path = './data_train/data_train/'\n",
    "\n",
    "def prepocess_timeseries(data_df):\n",
    "    c2h6, c2h2, ch4 = [], [], []\n",
    "    for i, row in data_df.iterrows():\n",
    "        c2h6.append(row['H2'] + row['C2H4'])\n",
    "        c2h2.append(row['H2'] + row['CO']*2)\n",
    "        ch4.append((row['H2'] + row['CO'])*2)        \n",
    "    data_df['C2H6'] = c2h6\n",
    "    data_df['C2H2'] = c2h2\n",
    "    data_df['CH4'] = ch4\n",
    "\n",
    "\n",
    "    for name in data_df.columns:\n",
    "        integr = np.concatenate(([0], it.cumtrapz(data_df[name])))\n",
    "        inv_integr = np.flip(np.concatenate(([0], it.cumtrapz(data_df[name].iloc[::-1]))))\n",
    "        data_df[name + \"_integ\"] = integr - inv_integr\n",
    "        data_df[name + \"_delta\"] = np.concatenate(([0], np.diff(data_df[name])))\n",
    "\n",
    "    for norm in norms:\n",
    "        if norm in data_df.columns:\n",
    "            data_df[norm + \"_norm\"] = data_df[norm] - norms[norm]\n",
    "    \n",
    "    return data_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 2100/2100 [01:29<00:00, 23.41it/s]\n"
     ]
    }
   ],
   "source": [
    "for file in tqdm(os.listdir(data_train_path)):\n",
    "    data_df = pd.read_csv(data_train_path + file)\n",
    "    data_df = prepocess_timeseries(data_df)\n",
    "    data_df.to_csv('./data_train/data_train_i/'+ file, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def flatten_data(\n",
    "                base_columns_names,\n",
    "                columns_repeat_n, \n",
    "                data_path, \n",
    "                file_names, \n",
    "                categories=None,):\n",
    "    columns = []\n",
    "    for i in range(columns_repeat_n):\n",
    "        for name in base_columns_names:\n",
    "            columns.append(str(i) + \"_\" + name)\n",
    "    if categories != None:\n",
    "        columns.append(\"predicted\")\n",
    "\n",
    "    data = []\n",
    "    for i in tqdm(range(len(file_names))):\n",
    "        new_row = pd.read_csv(data_path + file_names[i]).values.flatten()\n",
    "        if categories != None:\n",
    "            new_row = np.append(new_row, categories[i])\n",
    "        data.append(dict(zip(columns, new_row)))\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 2100/2100 [00:14<00:00, 147.07it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          0_H2      0_CO    0_C2H4    0_C2H2    0_C2H6     0_CH4  0_H2_integ  \\\n",
       "0     0.001202  0.029565  0.001069  0.060332  0.002271  0.061533   -0.664703   \n",
       "1     0.001875  0.030855  0.002613  0.063585  0.004487  0.065459   -0.923330   \n",
       "2     0.000947  0.021001  0.001025  0.042949  0.001973  0.043896   -0.474773   \n",
       "3     0.000720  0.017019  0.004584  0.034759  0.005304  0.035479   -0.398885   \n",
       "4     0.001791  0.009544  0.007192  0.020879  0.008983  0.022670   -0.809888   \n",
       "...        ...       ...       ...       ...       ...       ...         ...   \n",
       "2095  0.001043  0.009424  0.002751  0.019891  0.003793  0.020934   -0.589296   \n",
       "2096  0.000631  0.023220  0.003757  0.047072  0.004388  0.047703   -0.329963   \n",
       "2097  0.002005  0.020167  0.002409  0.042339  0.004415  0.044345   -1.156283   \n",
       "2098  0.002933  0.008451  0.000209  0.019834  0.003141  0.022767   -1.296014   \n",
       "2099  0.001545  0.024891  0.002929  0.051327  0.004473  0.052872   -0.736659   \n",
       "\n",
       "      0_H2_delta  0_CO_integ  0_CO_delta  ...  419_C2H6_integ  419_C2H6_delta  \\\n",
       "0            0.0  -14.043494         0.0  ...        1.524587        0.000025   \n",
       "1            0.0  -13.703315         0.0  ...        2.395344        0.000039   \n",
       "2            0.0  -10.968896         0.0  ...        1.066013        0.000028   \n",
       "3            0.0   -8.558554         0.0  ...        2.877564        0.000024   \n",
       "4            0.0   -4.542676         0.0  ...        4.671153        0.000033   \n",
       "...          ...         ...         ...  ...             ...             ...   \n",
       "2095         0.0   -4.551730         0.0  ...        2.200328        0.000033   \n",
       "2096         0.0  -10.964632         0.0  ...        2.290317        0.000028   \n",
       "2097         0.0   -9.822446         0.0  ...        2.491536        0.000035   \n",
       "2098         0.0   -4.914527         0.0  ...        1.786803        0.000030   \n",
       "2099         0.0  -11.736883         0.0  ...        2.197025        0.000005   \n",
       "\n",
       "      419_CH4_integ  419_CH4_delta  419_H2_norm  419_CH4_norm  419_C2H6_norm  \\\n",
       "0         29.416394       0.000159    -0.002706      0.080787       0.000924   \n",
       "1         29.253291       0.000119    -0.002236      0.071784       0.003284   \n",
       "2         22.887337       0.000188    -0.003184      0.069402      -0.001184   \n",
       "3         17.914879       0.000136    -0.003341      0.051405       0.004263   \n",
       "4         10.705129       0.000097    -0.002909      0.024430       0.009342   \n",
       "...             ...            ...          ...           ...            ...   \n",
       "2095      10.282052       0.000055    -0.002851      0.020077       0.002855   \n",
       "2096      22.589191       0.000163    -0.003895      0.065828       0.002627   \n",
       "2097      21.957459       0.000243    -0.000661      0.064187       0.003042   \n",
       "2098      12.421083       0.000152    -0.001238      0.043733       0.002299   \n",
       "2099      24.947084       0.000124    -0.003163      0.065023      -0.000570   \n",
       "\n",
       "      419_C2H2_norm  419_CO_norm  predicted  \n",
       "0          0.085693    -0.010901      550.0  \n",
       "1          0.076220    -0.015872     1093.0  \n",
       "2          0.074786    -0.016115      861.0  \n",
       "3          0.056946    -0.024956     1093.0  \n",
       "4          0.029538    -0.038876      488.0  \n",
       "...             ...          ...        ...  \n",
       "2095       0.025128    -0.041111     1093.0  \n",
       "2096       0.071923    -0.017191      805.0  \n",
       "2097       0.067047    -0.021246      476.0  \n",
       "2098       0.047171    -0.030896      550.0  \n",
       "2099       0.070386    -0.018326     1093.0  \n",
       "\n",
       "[2100 rows x 9661 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0_H2</th>\n      <th>0_CO</th>\n      <th>0_C2H4</th>\n      <th>0_C2H2</th>\n      <th>0_C2H6</th>\n      <th>0_CH4</th>\n      <th>0_H2_integ</th>\n      <th>0_H2_delta</th>\n      <th>0_CO_integ</th>\n      <th>0_CO_delta</th>\n      <th>...</th>\n      <th>419_C2H6_integ</th>\n      <th>419_C2H6_delta</th>\n      <th>419_CH4_integ</th>\n      <th>419_CH4_delta</th>\n      <th>419_H2_norm</th>\n      <th>419_CH4_norm</th>\n      <th>419_C2H6_norm</th>\n      <th>419_C2H2_norm</th>\n      <th>419_CO_norm</th>\n      <th>predicted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.001202</td>\n      <td>0.029565</td>\n      <td>0.001069</td>\n      <td>0.060332</td>\n      <td>0.002271</td>\n      <td>0.061533</td>\n      <td>-0.664703</td>\n      <td>0.0</td>\n      <td>-14.043494</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.524587</td>\n      <td>0.000025</td>\n      <td>29.416394</td>\n      <td>0.000159</td>\n      <td>-0.002706</td>\n      <td>0.080787</td>\n      <td>0.000924</td>\n      <td>0.085693</td>\n      <td>-0.010901</td>\n      <td>550.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.001875</td>\n      <td>0.030855</td>\n      <td>0.002613</td>\n      <td>0.063585</td>\n      <td>0.004487</td>\n      <td>0.065459</td>\n      <td>-0.923330</td>\n      <td>0.0</td>\n      <td>-13.703315</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>2.395344</td>\n      <td>0.000039</td>\n      <td>29.253291</td>\n      <td>0.000119</td>\n      <td>-0.002236</td>\n      <td>0.071784</td>\n      <td>0.003284</td>\n      <td>0.076220</td>\n      <td>-0.015872</td>\n      <td>1093.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000947</td>\n      <td>0.021001</td>\n      <td>0.001025</td>\n      <td>0.042949</td>\n      <td>0.001973</td>\n      <td>0.043896</td>\n      <td>-0.474773</td>\n      <td>0.0</td>\n      <td>-10.968896</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.066013</td>\n      <td>0.000028</td>\n      <td>22.887337</td>\n      <td>0.000188</td>\n      <td>-0.003184</td>\n      <td>0.069402</td>\n      <td>-0.001184</td>\n      <td>0.074786</td>\n      <td>-0.016115</td>\n      <td>861.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000720</td>\n      <td>0.017019</td>\n      <td>0.004584</td>\n      <td>0.034759</td>\n      <td>0.005304</td>\n      <td>0.035479</td>\n      <td>-0.398885</td>\n      <td>0.0</td>\n      <td>-8.558554</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>2.877564</td>\n      <td>0.000024</td>\n      <td>17.914879</td>\n      <td>0.000136</td>\n      <td>-0.003341</td>\n      <td>0.051405</td>\n      <td>0.004263</td>\n      <td>0.056946</td>\n      <td>-0.024956</td>\n      <td>1093.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.001791</td>\n      <td>0.009544</td>\n      <td>0.007192</td>\n      <td>0.020879</td>\n      <td>0.008983</td>\n      <td>0.022670</td>\n      <td>-0.809888</td>\n      <td>0.0</td>\n      <td>-4.542676</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>4.671153</td>\n      <td>0.000033</td>\n      <td>10.705129</td>\n      <td>0.000097</td>\n      <td>-0.002909</td>\n      <td>0.024430</td>\n      <td>0.009342</td>\n      <td>0.029538</td>\n      <td>-0.038876</td>\n      <td>488.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2095</th>\n      <td>0.001043</td>\n      <td>0.009424</td>\n      <td>0.002751</td>\n      <td>0.019891</td>\n      <td>0.003793</td>\n      <td>0.020934</td>\n      <td>-0.589296</td>\n      <td>0.0</td>\n      <td>-4.551730</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>2.200328</td>\n      <td>0.000033</td>\n      <td>10.282052</td>\n      <td>0.000055</td>\n      <td>-0.002851</td>\n      <td>0.020077</td>\n      <td>0.002855</td>\n      <td>0.025128</td>\n      <td>-0.041111</td>\n      <td>1093.0</td>\n    </tr>\n    <tr>\n      <th>2096</th>\n      <td>0.000631</td>\n      <td>0.023220</td>\n      <td>0.003757</td>\n      <td>0.047072</td>\n      <td>0.004388</td>\n      <td>0.047703</td>\n      <td>-0.329963</td>\n      <td>0.0</td>\n      <td>-10.964632</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>2.290317</td>\n      <td>0.000028</td>\n      <td>22.589191</td>\n      <td>0.000163</td>\n      <td>-0.003895</td>\n      <td>0.065828</td>\n      <td>0.002627</td>\n      <td>0.071923</td>\n      <td>-0.017191</td>\n      <td>805.0</td>\n    </tr>\n    <tr>\n      <th>2097</th>\n      <td>0.002005</td>\n      <td>0.020167</td>\n      <td>0.002409</td>\n      <td>0.042339</td>\n      <td>0.004415</td>\n      <td>0.044345</td>\n      <td>-1.156283</td>\n      <td>0.0</td>\n      <td>-9.822446</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>2.491536</td>\n      <td>0.000035</td>\n      <td>21.957459</td>\n      <td>0.000243</td>\n      <td>-0.000661</td>\n      <td>0.064187</td>\n      <td>0.003042</td>\n      <td>0.067047</td>\n      <td>-0.021246</td>\n      <td>476.0</td>\n    </tr>\n    <tr>\n      <th>2098</th>\n      <td>0.002933</td>\n      <td>0.008451</td>\n      <td>0.000209</td>\n      <td>0.019834</td>\n      <td>0.003141</td>\n      <td>0.022767</td>\n      <td>-1.296014</td>\n      <td>0.0</td>\n      <td>-4.914527</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.786803</td>\n      <td>0.000030</td>\n      <td>12.421083</td>\n      <td>0.000152</td>\n      <td>-0.001238</td>\n      <td>0.043733</td>\n      <td>0.002299</td>\n      <td>0.047171</td>\n      <td>-0.030896</td>\n      <td>550.0</td>\n    </tr>\n    <tr>\n      <th>2099</th>\n      <td>0.001545</td>\n      <td>0.024891</td>\n      <td>0.002929</td>\n      <td>0.051327</td>\n      <td>0.004473</td>\n      <td>0.052872</td>\n      <td>-0.736659</td>\n      <td>0.0</td>\n      <td>-11.736883</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>2.197025</td>\n      <td>0.000005</td>\n      <td>24.947084</td>\n      <td>0.000124</td>\n      <td>-0.003163</td>\n      <td>0.065023</td>\n      <td>-0.000570</td>\n      <td>0.070386</td>\n      <td>-0.018326</td>\n      <td>1093.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2100 rows × 9661 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "data_train_i_path = './data_train/data_train_i/'\n",
    "example_df = pd.read_csv(data_train_i_path + '2_trans_2.csv')\n",
    "out_df = flatten_data(example_df.columns, len(example_df), data_train_i_path, train_df['id'].to_list(), train_df['predicted'].to_list())\n",
    "out_df = out_df.loc[:, (df != 0).any(axis=0)]\n",
    "out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    " X, y = out_df.drop('predicted', axis=1), out_df['predicted']\n",
    " X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-c80c7440b12b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mae\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#clf.fit(out_df.drop('category', axis=1), out_df['category'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "reg = RandomForestRegressor(criterion=\"mae\", n_jobs=-1)\n",
    "reg.fit(X_train, y_train)\n",
    "#clf.fit(out_df.drop('category', axis=1), out_df['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.score(X_test, y_test)"
   ]
  },
  {
   "source": [
    "# Тенсорка входит в здание"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = out_df['predicted'}\n",
    "dataset = tf.data.Dataset.from_tensor_slices((out_df.drop('predicted', axis=1).values, target.values-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset.shuffle(len(out_df)).batch(1)\n",
    "def get_compiled_model():\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(500, activation='relu'),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(30, activation='relu'),\n",
    "    tf.keras.layers.Dense(4)\n",
    "  ])\n",
    "\n",
    "  model.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      " 948/2100 [============>.................] - ETA: 6s - loss: 0.4437 - accuracy: 0.8344"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-83cbca72f3cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_compiled_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/transformer/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1103\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/transformer/venv/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \"\"\"\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "model.fit(train_dataset, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_dir = './data_test/data_test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 900/900 [00:40<00:00, 22.28it/s]\n"
     ]
    }
   ],
   "source": [
    "for file in tqdm(os.listdir(data_test_dir)):\n",
    "    data_df = pd.read_csv(data_test_dir + file)\n",
    "    data_df = prepocess_timeseries(data_df)\n",
    "    data_df.to_csv('./data_test/data_test_i/'+ file, index=None)\n",
    "example_test_df = pd.read_csv(data_test_dir + os.listdir(data_test_dir)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 900/900 [00:01<00:00, 516.75it/s]\n"
     ]
    }
   ],
   "source": [
    "data_test_i_dir = './data_test/data_test_i/'\n",
    "example_test_df = pd.read_csv(data_test_i_dir + os.listdir(data_test_dir)[0])\n",
    "test_file_names = os.listdir(data_test_i_dir)\n",
    "test_complete_df = flatten_data(example_test_df.columns, len(example_test_df), data_test_i_dir, test_file_names)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = []\n",
    "predicts = clf.predict(test_complete_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'id': os.listdir(data_test_dir), 'category': predicts.astype('int')}, index=None).to_csv('test.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}